# -*- coding: utf-8 -*-
"""COSE-474-02-Assignment_1-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/107jd4DDZ5WhB9niLfxU1adBwsMjkDBcn

## Assignment 1

âš ï¸ **Important! Submission Requirements**

1. **Do NOT clear notebook logs or outputs.**  
   Every output cell must remain visible (e.g., print logs, progress logs, summary messages).

2. **The notebook must be *self-contained*.**  
   - You should be able to run it **from top to bottom once** without any manual steps.  
   - No need for any external scripts, config files, or multiple runs.
   - Creating multiple cells/blocks is OK.

3. **Single `.ipynb` implementation.**  
   Do not create separate Python files or folders other than the generated image output directory.

4. **Clean, readable, and well-commented code.**

5. **Submission file name format:**  
   â†’ `studentID_name.zip`  
   (Example: `2025000000_jungbeomlee.zip`)
   - This file should contain `best.pth`, and `COSE-474-02-Assignment_1.ipynb`. DO NOT include `mnist_images` folder.
---

## Python familiarization
**ğŸ¯ Goal**

Warm up with Python and the PyTorch data ecosystem by:

1. Loading the **MNIST** dataset (train & test).  
2. Randomly splitting 10% of the training set into a validation set.  
3. Exporting the images to a folder structure on disk in the format `<split>/<class>/<zero_padded>.jpg`, e.g., `train/0/00000.jpg`, `val/1/00000.jpg`, `test/3/00000.jpg`.


**What youâ€™ll practice**

1. Using `torchvision.datasets.MNIST` to download & access data  
2. Basic Python file I/O with `pathlib` / `os`  
3. Converting tensors/PIL images and saving to disk with `PIL`  
4. Performing a **manual dataset split** (train â†’ train/val)  
5. Implementing **progress tracking and sanity checks**

**Dataset**

- MNIST consists of:
  - **60,000 training** images  
  - **10,000 test** images  
- Each image: 28Ã—28 pixels, grayscale, labeled **0â€“9**.

**Your task**

1. **Download** both MNIST `train` and `test` datasets using `torchvision.datasets.MNIST`.  

2. **Split** the training dataset:
   - Randomly take **10% of the train samples** for **validation**.  
   - Do not use automatic random split libraries (e.g., `torch.utils.data.random_split()`). Try to manually implement the random splitting codes.
3. **Iterate** through the dataset and save each sample as a JPEG image into the corresponding split / class folder.
Example target layout:
```
mnist_images/
train/
0/
00000.jpg
00001.jpg
1/
00000.jpg
...
val/
0/
00000.jpg
...
test/
0/
00000.jpg
...
```
4. Use **zero-padded 5-digit filenames** for all images  
(e.g., `00000.jpg`, `00001.jpg`, â€¦) so lexicographic order matches numeric order.
5. Keep the images **grayscale** (`mode='L'`) and save as `.jpg`
"""

# Implement your codes here!

from torchvision import datasets

train_dataset = datasets.MNIST(root="./data", train=True, download=True)
test_dataset  = datasets.MNIST(root="./data", train=False, download=True)

# data load test
print(f"Train data: {len(train_dataset)}")
print(f"Test data: {len(test_dataset)}")

# ìˆ˜ë™ data split
def train_data_split(train_dataset, val_ratio=0.1, seed=42):
    import random

    # ì¬í˜„ ê°€ëŠ¥ì„± ìœ„í•œ ì¶”ê°€
    random.seed(seed)

    # split ìœ„í•œ ì „ì²´ index list ìƒì„±
    total_size = len(train_dataset)
    indices = list(range(total_size))

    # random split ë³´ì¥ì„ ìœ„í•´ ì„ì˜ë¡œ idxë¥¼ ì„ëŠ”ë‹¤.
    random.shuffle(indices)

    # ë¶„í•  ê¸°ì¤€ì  ê³„ì‚°
    num_val = int(total_size * val_ratio)
    train_indices = indices[num_val:]
    val_indices = indices[:num_val]

    # ì„ì€ dataë¥¼ ë¹„ìœ¨ëŒ€ë¡œ ë‚˜ëˆˆë‹¤.
    train_data = [train_dataset[i] for i in train_indices]
    val_data = [train_dataset[i] for i in val_indices]

    # spilt í›„ data í¬ê¸°
    print(f"[After Split] Train data: {len(train_data)}")
    print(f"[After Split] Val data: {len(val_data)}")

    return train_data, val_data

train_data, val_data = train_data_split(train_dataset, val_ratio=0.1, seed=42)

# data ì €ì¥
import os
from PIL import Image

## í—¬í¼ í•¨ìˆ˜
def make_dir(path: str):
    os.makedirs(path, exist_ok=True)
## ë³¸ í•¨ìˆ˜
def save_split_as_jpeg(split_data, split_name: str, out_root: str= "mnist_images"):
    """
    split_data: â€œì €ì¥í•  ë°ì´í„°(ì´ë¯¸ì§€, ë¼ë²¨ ìŒ)â€ ê·¸ ìì²´, [(PIL.Image, label), ...] í˜•íƒœ (train_data/val_data/test_dataset)
    split_name: â€œtrain / val / test ì¤‘ ì–´ë–¤ ì„¸íŠ¸ì¸ì§€â€ í‘œì‹œìš© ì´ë¦„, 'train' | 'val' | 'test'
    out_root:   ìµœìƒìœ„ ì¶œë ¥ í´ë”
    ê·œì¹™:
      - mnist_images/train/0/00000.jpg ...
      - íŒŒì¼ëª… 5ìë¦¬ zero-padding, ê·¸ë ˆì´ìŠ¤ì¼€ì¼ 'L', .jpg
      - ê° í´ë˜ìŠ¤ í´ë”ë§ˆë‹¤ 00000ë¶€í„° ì¹´ìš´íŠ¸ ì‹œì‘
    """
    from collections import defaultdict
    split_root = os.path.join(out_root, split_name)
    # í´ë˜ìŠ¤ í´ë” ìƒì„± ë° í´ë˜ìŠ¤ë³„ ì¹´ìš´í„° ì¤€ë¹„
    # ì—†ëŠ” í‚¤(label)ê°€ ë“¤ì–´ì˜¤ë©´ ìë™ìœ¼ë¡œ 0ì„ ë°˜í™˜í•˜ë„ë¡ defaultdict ì‚¬ìš©
    class_counters = defaultdict(int)
    for cls in range(10):
        make_dir(os.path.join(split_root, str(cls)))

    # ì´ë¯¸ì§€ ì €ì¥
    for img, label in split_data:
      # tensor -> PIL
      if not isinstance(img, Image.Image):
        img = Image.fromarray(img.numpy().squeeze())

      # gray scale ë³´ì¥
      img = img.convert('L')

      idx_in_class = class_counters[label]
      # zero-padding
      filename = f"{idx_in_class:05d}.jpg"
      # ì €ì¥
      save_path = os.path.join(split_root, str(label), filename)
      img.save(save_path, format="JPEG")
      class_counters[label] += 1

    # ìš”ì•½
    per_class_counts = {c: cnt for c, cnt in sorted(class_counters.items())}
    total = sum(per_class_counts.values())
    print(f"[Saved {split_name}] total={total} per_class={per_class_counts}")

# ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œ
save_split_as_jpeg(train_data, "train", out_root="mnist_images")
save_split_as_jpeg(val_data,   "val",   out_root="mnist_images")

# test_datasetì€ torch Datasetì´ë¯€ë¡œ (img, label) íŠœí”Œë¡œ ìˆœíšŒ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±
test_list = [test_dataset[i] for i in range(len(test_dataset))]
save_split_as_jpeg(test_list, "test", out_root="mnist_images")

import matplotlib.pyplot as plt
from PIL import Image

# ê° splitì—ì„œ 0ë²ˆ í´ë˜ìŠ¤ì˜ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê²½ë¡œ
img_path_train = "mnist_images/train/0/00000.jpg"
img_path_val = "mnist_images/val/0/00000.jpg"
img_path_test = "mnist_images/test/0/00000.jpg"

# ì´ë¯¸ì§€ ì €ì¥ì´ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì•„ë¬´ìƒê°ì—†ì´ í–ˆëŠ”ë°
# ì•„ë˜ ë‘ë²ˆì§¸ ì†Œë¬¸ì œì— í¬í•¨ë˜ì–´ ìˆì—ˆë‹¤...
# ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
img_train = Image.open(img_path_train)
img_val = Image.open(img_path_val)
img_test = Image.open(img_path_test)

# ì‹œê°í™”
plt.figure(figsize=(9,3))

plt.subplot(1,3,1)
plt.imshow(img_train, cmap='gray')
plt.title("Train / Class 0")
plt.axis('off')

plt.subplot(1,3,2)
plt.imshow(img_val, cmap='gray')
plt.title("Val / Class 0")
plt.axis('off')

plt.subplot(1,3,3)
plt.imshow(img_test, cmap='gray')
plt.title("Test / Class 0")
plt.axis('off')

plt.tight_layout()
plt.show()

"""## PyTorch Custom DataLoader

**Objective**

PyTorch provides pre-defined data loaders for popular datasets (e.g., MNIST). However, in practice, you often need to create your own data loader. So, let's practice implementing a custom data loader!

Using the images you exported above (folder layout: `mnist_images/<split>/<class>/<00000.jpg>`), implement a **custom `torch.utils.data.Dataset`** and wrap it with **`DataLoader`** for training/validation/test.

**Requirements**

1. Assume the data directory structure above
2. Implement a dataset class that:
- Takes arguments `split` where `split` âˆˆ {'train', 'val', 'test'}
- Scans class folders (`0`â€“`9`) and builds `(filepath, label)` index
- Loads each image as **grayscale ('L')**
- Applies user-defined `transform`
- Returns `(image_tensor, label_int)`
3. Create `DataLoader`s with configurable:
- `batch_size`, `shuffle`, `num_workers`
- shuffle=True for train, False for val/test
4. Provide a **quick sanity check**:
- Print dataset size per split
- Fetch one batch with `batch_size=10` from 'train' and visualize each image and label with matplotlib

**Required transforms**
- To tensor: `ToTensor()` (â†’ shape `[1, H, W]`, values in `[0,1]`)
- Normalization: `Normalize(mean=[0.5], std=[0.5])`


"""

# Implement your codes here!

import os
from PIL import Image
from pathlib import Path # PathëŠ” ë¬¸ìì—´ ê¸°ë°˜ ê²½ë¡œ("mnist_images/train/0")ë¥¼ ê°ì²´ í˜•íƒœë¡œ ë‹¤ë£¨ê²Œ í•´ì£¼ëŠ” í´ë˜ìŠ¤

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import matplotlib.pyplot as plt

root_dir = "mnist_images"
batch_size = 64 # Your own value
num_workers = 2 # Your own value
pin_memory = torch.cuda.is_available() # cuda ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

class MNISTFolderDataset(Dataset):
    def __init__(self, root: Path, split: str, transform=None):
        assert split in {"train", "val", "test"}, "split must be one of {'train', 'val', 'test'}"
        self.root = Path(root)
        self.split = split
        self.transform = transform

        split_root = self.root / split
        if not split_root.is_dir():
            raise ValueError(f"Invalid split directory: {split_root}")

        # (filepath, label) list ìƒì„±
        """
        [
        ("mnist_images/train/0/00000.jpg", 0),
        ("mnist_images/train/0/00001.jpg", 0),
        ("mnist_images/train/1/00000.jpg", 1),
        ...
        ]
        """
        self.samples = []
        for cls in range(10): # ë°ì´í„°ì…‹ì˜ labelì´ 0~9ê¹Œì§€ë‹ˆê¹Œ range(10)
            cls_dir = split_root / str(cls)
            # ë§Œì•½ í´ë”ê°€ ì—†ì„ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥
            if not cls_dir.is_dir():
                print(f"[WARN] class í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.: {cls_dir}")
                continue
            # í´ë” ì•ˆì˜ ëª¨ë“  .jpg íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            for p in sorted(cls_dir.glob("*.jpg")):
                self.samples.append((str(p), int(cls))) # ê° ì´ë¯¸ì§€ì˜ ê²½ë¡œ(p)ì™€ ë¼ë²¨ ë²ˆí˜¸(cls)ë¥¼ íŠœí”Œë¡œ ë¬¶ì–´ì„œ ì €ì¥
        # í˜¹ì‹œ ë°ì´í„°ê°€ í•˜ë‚˜ë„ ì•ˆ ë“¤ì–´ì™”ë‹¤ë©´ (í´ë”ê°€ ë¹„ì–´ìˆê±°ë‚˜ ê²½ë¡œ ì˜ëª» ì§€ì •) ì—ëŸ¬ ë°œìƒ
        if len(self.samples) == 0:
            raise RuntimeError(f"No samples found in {split_root}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path, label = self.samples[idx] # ë°ì´í„° í•˜ë‚˜ êº¼ë‚´ì˜¤ê¸°
        img = Image.open(path).convert("L") # ì´ë¯¸ì§€ gray scaleë¡œ êº¼ë‚´ê¸°
        if self.transform is not None: # Tensorë¡œ ë³€í™˜ ë° ì •ê·œí™”
            img = self.transform(img)
        return img, label # í•˜ë‚˜ì˜ ìƒ˜í”Œ ë¦¬í„´

transform = transforms.Compose([
    # ì´ë¯¸ì§€ tensorë¡œ ë³€í™˜ ë° ì •ê·œí™”
    transforms.ToTensor(),  # [H, W] â†’ [1, H, W] í…ì„œë¡œ ë³€í™˜
    transforms.Normalize(mean=[0.5], std=[0.5])   # [0,1] â†’ [-1,1]ë¡œ ì •ê·œí™”
])

train_ds = MNISTFolderDataset(root_dir, "train", transform=transform)
val_ds   = MNISTFolderDataset(root_dir, "val",   transform=transform)
test_ds  = MNISTFolderDataset(root_dir, "test",  transform=transform)

train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,
                          num_workers=num_workers, pin_memory=pin_memory)
val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,
                          num_workers=num_workers, pin_memory=pin_memory)
test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,
                          num_workers=num_workers, pin_memory=pin_memory)


# implement sanity check here
print(f"Train dataset size: {len(train_ds)}")
print(f"Val dataset size: {len(val_ds)}")
print(f"Test dataset size: {len(test_ds)}")

# recover the normalized images into the original space
def denorm(x):
    # x: tensor in [-1,1]
    return (x * 0.5) + 0.5  # -> [0,1]

# implement your code to visualize the actual samples using matplotlib using denorm function above
# Sanity check: trainì—ì„œ 10ì¥ ë½‘ì•„ ì‹œê°í™”
vis_loader = DataLoader(train_ds, batch_size=10, shuffle=True,
                        num_workers=num_workers, pin_memory=pin_memory)
imgs, labels = next(iter(vis_loader))
imgs = denorm(imgs)  # ì‹œê°í™”ìš© ë³µêµ¬

plt.figure(figsize=(12, 3))
for i in range(10):
    plt.subplot(1, 10, i+1)
    plt.imshow(imgs[i, 0].cpu(), cmap='gray')  # [B,1,H,W] -> [H,W]
    plt.title(int(labels[i]))
    plt.axis('off')
plt.suptitle("Sanity Check: One Batch from 'train' (10 samples)")
plt.tight_layout()
plt.show()

"""## Model Architecture

Design and implement a simple convolutional neural network for the MNIST dataset.
You are provided with a description of the architecture below, and your task is to implement the model class so that each layerâ€™s output shape matches the description exactly.


**Model Description**

You may need to include appropriate activation functions in between.

0. input: (B, 1, 28, 28)
1. conv1: output (B, 32, 28, 28)
2. conv2: output (B, 64, 28, 28)
3. maxpool1: output (B, 64, 14, 14)
4. conv3: output (B, 128, 14, 14)
5. conv4: output (B, 128, 14, 14)
6. maxpool2: output (B, 128, 7, 7)
7. flatten: output (B, 128x7x7)
8. fc1: output (B, 256)
9. fc2: output (B, `n_class`)


**Requirements**
1. **Implement a model class** (`MyConvNet`).
- Use `nn.Conv2d`, `nn.ReLU`, `nn.MaxPool2d`, and `nn.Linear` layers.
- Adjust **`kernel_size` / `stride` / `padding`** so that each output shape matches the description above.
2. **Sanity check with zero input**  
- Create a zero tensor with shape **`[batch=10, channels=1, height=28, width=28]`** and run it through the model. Print the output shape.
3. Implementation Constraints
- Keep the architecture identical to the description.
- No BatchNorm or Dropout for this time.

"""

# Implement your codes here!

import torch
import torch.nn as nn

# í•™ìŠµ ì§„í–‰ì„ ìœ„í•œ ì¥ì¹˜ ì„ ì–¸
# ê°€ëŠ¥í•˜ë‹¤ë©´ GPU ì‚¬ìš©
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

class MyConvNet(nn.Module):
    def __init__(self, n_class=10):
        super().__init__()

        # Conv layers
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)
        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)

        # Fully connected layers
        self.fc1 = nn.Linear(128 * 7 * 7, 256)
        self.fc2 = nn.Linear(256, n_class)

        # Activation
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.conv1(x))   # (B,32,28,28)
        x = self.relu(self.conv2(x))   # (B,64,28,28)
        x = self.pool1(x)              # (B,64,14,14)
        x = self.relu(self.conv3(x))   # (B,128,14,14)
        x = self.relu(self.conv4(x))   # (B,128,14,14)
        x = self.pool2(x)              # (B,128,7,7)
        x = torch.flatten(x, 1)        # (B,128*7*7)
        x = self.relu(self.fc1(x))     # (B,256)
        x = self.fc2(x)                # (B,n_class)
        return x

# define your model here & do the sanity check
model = MyConvNet().to(device)
print(model)

# sanity check
dummy_input = torch.zeros((10, 1, 28, 28)).to(device)
output = model(dummy_input)
print(f"Output shape: {output.shape}")

"""## Training with GPUs

**Goal**

Train your `MyConvNet` using **SGD** with **momentum** and **weight decay**. For here, do not use `test` set yet.

**Requirements**

0. Use GPUs!
1. **Optimizer**: `torch.optim.SGD`  
- **Momentum**: must be used (non-zero)  
- **Weight Decay**: must be used (non-zero)
2. **Loss**: `nn.CrossEntropyLoss()`
3. **Logging**:
- Define `history` dictionary with the keys of "train_loss" and "val_acc".
- **Store**: `train_loss` (epoch-average) and `val_acc` (epoch) into lists for later plotting
4. **Early Stopping**:  
- Keep track of best `val_acc`  
- When `val_acc` improves against the historical best, **save** model weights to `best.pth`  
- If no improvement for `patience` epochs, **stop**
5. Once your training is done, you should have:
- Plot two figures, each of `history["train_loss"]` and `history["val_acc"]` with epochs.
- Saved `best.pth` containing the best-performing weights on validation
"""

# Implement your codes here!

import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from pathlib import Path

device = "cuda"
print("Using device:", device)

# define your hyper-parameters
max_epochs = 30
lr = 0.01 # learning rate
momentum = 0.9 # optimizer ê´€ì„±
weight_decay = 5e-4 # L2 ê·œì œ
patience = 5 # early stop ì¡°ê±´

# define your model, loss, and optimizer
model = MyConvNet(n_class=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=lr,
                      momentum=momentum, weight_decay=weight_decay)

# define history for logging
history = {
    "train_loss": [],
    "val_acc": [],
}

# í—¬í¼ í•¨ìˆ˜: val splitì—ì„œ ì •í™•ë„ í‰ê°€
@torch.no_grad()
def evaluate_acc(model, loader, device):
    model.eval()
    correct, total = 0,0 # ëˆ„ì  ì •ë‹µ ìˆ˜ ë° í‘œë³¸ ìˆ˜ ì¹´ìš´í„°
    for imgs, labels in loader:
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs) # [B, n_class]
        preds = logits.argmax(dim=1) # [B]
        correct += (preds == labels).sum().item() # ë°°ì¹˜ ë‚´ì—ì„œ ì˜ˆì¸¡ê³¼ ì •ë‹µì´ ê°™ì€ ìœ„ì¹˜ë¥¼ boolean í…ì„œë¡œ ë§Œë“  ë’¤, sum()ìœ¼ë¡œ ë§ì¶˜ ê°œìˆ˜ë¥¼ í•©
        total += labels.size(0) # ë°°ì¹˜ í¬ê¸°ë§Œí¼ í‘œë³¸ ìˆ˜ë¥¼ ëˆ„ì 
    return correct / max(total, 1) # í˜¹ì‹œë‚˜ ë¹ˆ loader ì¼ ê²½ìš° 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì—ëŸ¬ ë°©ì§€

# training
best_acc = 0.0
no_improve = 0

for epoch in range(1, max_epochs + 1):
    model.train()
    running_loss, n_batches = 0.0, 0 # í•œ epoch ë™ì•ˆ loss ëˆ„ì  í›„ í‰ê·  ë° ì²˜ë¦¬í•œ ë¯¸ë‹ˆë°°ì¹˜ ê°œìˆ˜

    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad() # ê¸°ìš¸ê¸° ì´ˆê¸°í™”
        logits = model(imgs) # [B, n_class], ìˆœì „íŒŒ
        loss = criterion(logits, labels) # loss ê³„ì‚°
        loss.backward() # ì—­ì „íŒŒ
        optimizer.step() # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸

        running_loss += loss.item() # í˜„ì¬ ë°°ì¹˜ì˜ ì†ì‹¤ ëˆ„ì 
        n_batches += 1

    train_loss = running_loss / max(n_batches, 1) # í•œ epoch ë™ì•ˆ í‰ê·  ì†ì‹¤
    val_acc = evaluate_acc(model, val_loader, device)

    history["train_loss"].append(train_loss)
    history["val_acc"].append(val_acc)

    print(f"[Epoch {epoch:02d}] train_loss={train_loss:.4f} | val_acc={val_acc:.4f}")


    if val_acc > best_acc:
        best_acc = val_acc
        torch.save(model.state_dict(), "best.pth")
        print(f"New best! val_acc={best_acc:.4f} (saved to best.pth)")
        no_improve = 0
    else:
        no_improve += 1
        if no_improve >= patience:
            print(f"Early stopping triggered (patience={patience})")
            break

print(f"Best validation accuracy: {best_acc:.4f}")

# plot training loss and validation accuracy by epochs
plt.figure()
plt.plot(history["train_loss"])
plt.title("Train Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.grid(True)
plt.show()

plt.figure()
plt.plot(history["val_acc"])
plt.title("Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

"""## Evaluation with Test Set

**Objective**

Load the best-performing model checkpoint (`best.pth`) saved during training above and evaluate it on the **test dataset** to measure the final **test accuracy**. For here, no retraining allowed â€” this block only loads and evaluates.

Your model must achieve **at least 99% test accuracy** on MNIST.  
If your test accuracy is **below 99%**, you are required to **revisit and iterate on your training block** by adjusting hyperparameters (e.g., learning rate, momentum, weight decay, batch size, or number of epochs) until the requirement is met.

**Requirements**

1. Model Loading
- Recreate the same model architecture (`MyConvNet`) as used for training.
- Load the trained weights:
     ```python
     model.load_state_dict(torch.load("best.pth", map_location=device))
     ```
- Set the model to evaluation mode (`model.eval()`).

2. **Evaluation**
- Use your **test_loader** defined above, with the same preprocessing and normalization as during training.
- Wrap inference inside `torch.no_grad()` to disable gradients.
- Compute **overall test accuracy**

3. **Reporting**
- Print results clearly:
     ```
     Total test samples: <num>
     Correct predictions: <num>
     Test accuracy: <value>
     ```
- You must achieve **â‰¥ 99%** accuracy.  
     If below, go back and **retrain** (adjust hyperparameters, increase epochs, etc.) until it meets the target.



"""

# Implement your codes here!
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

# load model from best.pth
model = MyConvNet(n_class=10).to(device)
model.load_state_dict(torch.load("best.pth", map_location=device))

# evaluate
model.eval()

# iterate test samples using test_loader above
total, correct = 0, 0
with torch.no_grad():
    for imgs, labels in test_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        logits = model(imgs)
        preds = logits.argmax(dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

test_acc = correct / max(total,1)

# print the final result
print(f"Total test samples: {total}")
print(f"Correct predictions: {correct}")
print(f"Test accuracy: {test_acc:.4f}")

# ê¸°ì¤€ ë‹¬ì„± ì—¬ë¶€ í™•ì¸
if test_acc < 0.99:
    print("Test accuracy < 0.99. Revisit training (lr/momentum/weight_decay/batch_size/epochs ë“± ì¡°ì •).")
else:
    print("Requirement met: Test accuracy â‰¥ 0.99")

"""## Submission

When you are ready to submit your materials:
1. Download best.pth to your local computer
2. Download your COSE-474-02-Assignment_1.ipynb file (make sure **all outputs are kept**) to your local computer
3. Create a zip file (e.g., 2025000000_jungbeomlee.zip), containing `best.pth` and `COSE-474-02-Assignment_1.ipynb` (DO NOT include mnist_images folder, it's too large!)



"""

# best.pth ë° ì´ë¯¸ì§€ ë¶„ë¥˜ í™•ì¸ì„ ìœ„í•œ ë‹¤ìš´ë¡œë“œ ìš© cell
import os

for split in ["train", "val", "test"]:
    total = 0
    for cls in range(10):
        count = len(os.listdir(f"mnist_images/{split}/{cls}"))
        print(f"{split} - class {cls}: {count}")
        total += count
    print(f"{split} total: {total}\n")

# ì œì¶œ ìœ„í•œ ì£¼ì„ ì²˜ë¦¬
"""
!zip -r mnist_images.zip mnist_images
from google.colab import files
files.download("mnist_images.zip")

from google.colab import files
files.download("best.pth")
"""